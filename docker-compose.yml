services:
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    ports:
      - "8000:8000"
    environment:
      OPENAI_API_KEY: ${OPENAI_API_KEY}
      ANTHROPIC_API_KEY: ${ANTHROPIC_API_KEY}
      PINECONE_API_KEY: ${PINECONE_API_KEY}
      PINECONE_INDEX_NAME: ${PINECONE_INDEX_NAME}
      AI_PROVIDER: ${AI_PROVIDER:-openai}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      CHAT_RATE_LIMIT_PER_MIN: ${CHAT_RATE_LIMIT_PER_MIN:-20}
      LLM_TIMEOUT_SECONDS: ${LLM_TIMEOUT_SECONDS:-30}
      LLM_MAX_RETRIES: ${LLM_MAX_RETRIES:-2}
    volumes:
      - backend_data:/app/data
    tmpfs:
      - /tmp
    init: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    ports:
      - "3000:3000"
    environment:
      NEXT_PUBLIC_API_URL: http://backend:8000
    depends_on:
      backend:
        condition: service_healthy
    read_only: true
    tmpfs:
      - /tmp
    init: true
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "-qO-", "http://localhost:3000/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

volumes:
  backend_data:
